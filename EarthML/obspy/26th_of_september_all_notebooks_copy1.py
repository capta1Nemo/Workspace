# -*- coding: utf-8 -*-
"""26th of September All Notebooks-Copy1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WMouuSIDD6ShjtaPax7P4D9I-EQ6lZ-0

# 26th of September

- **This notebook/report actually consists of 8 separate notebooks:**
   - **Raw data with ObsPy and Threshold Effect**
   - **Raw data with Eqcorrscan and Threshold Effect (Appendix 1)**
   - **Preprocessed data with ObsPy and Threshold Effect**
   - **Preprocessed data with Eqcorrscan and Threshold Effect (Appendix 2)**
   - **Raw data with ObsPy and Window-size Effect**
   - **Raw data with Eqcorrscan and Window-size Effect (Appendix 3)**
   - **Preprocessed data with ObsPy and Window-size Effect**
   - **Preprocessed data with Eqcorrscan and Window-size Effect(Appendix 4)**

- **Warning: You may get confused about why we did not use int module on the Eqcorrscan models. Its reason is: the eqcorrscan algorithm already uses the int module. Also, we showed the Eqcorrscan as Appendix/Attempts since its detection times are given twice(caused by the source code), but the rest is correct. And, on the histograms, the blue lines are shown two times of the actual length(because of the algortihm counts twice)**
"""

from __future__ import print_function
import obspy
from obspy import read, read_inventory, read_events
import matplotlib.pyplot as plt
import numpy as np
from obspy.signal.trigger import classic_sta_lta, plot_trigger,coincidence_trigger, recursive_sta_lta, z_detect,trigger_onset
from pprint import pprint
import eqcorrscan
from eqcorrscan.utils.picker import stalta_pick

from os.path import join as opj
import sys
if sys.version_info[0] < 3:
    from StringIO import StringIO
else:
    from io import StringIO
    import operator
import functools
import pandas as pd
import re

"""# Preparing Catalog"""

workdir = '/Users/korayaydogan/Downloads/SLVT'
with open(opj(workdir, 'hyp.out')) as f:
    hyp_txt = f.read()
# two new lines and a bunch of space between each recod
record_separator = '\n +\n'

hyp_split = re.split(record_separator, hyp_txt)
assert hyp_split[-1]==''
hyp_split_trim = [s for s in hyp_split if s]
# just one empty record
assert len(hyp_split_trim) == len(hyp_split) - 1

# pick the first line of each metadata
hyp_meta_str_list = [s.split('\n')[0] for s in hyp_split_trim]
hyp_meta_str = '\n'.join(hyp_meta_str_list)
hyp_meta_check = pd.read_csv(StringIO(hyp_meta_str), header=None, delim_whitespace=True)


#the fallowing numbers indicate that the interval of the number of digits
#for example "2019" has 4 digits, so for this info we split as (0,5)
colspecs_hyp_meta = [(0,5),(6,8),(8,10),(11,13),(13,15),(16,21),(21,22),
                     (23,30),(31,38),(39,43),(44,48),(49,51),(52,56),
                     (72,75),(75,79),(79,80)]
hyp_meta =pd.read_fwf(StringIO(hyp_meta_str),
                      colspecs=colspecs_hyp_meta,
                      header=None)

colspecs_hyp_list = [(0,5),(6,8),(8,14),(14,15),(15,17),
                  (18,20),(20,22),(23,29),(29,33),
                  (34,40),(41,45),(46,51),(52,56),
                  (57,60),(61,63),(63,68),(68,70),
                  (70,75),(75,80)]
hyp_list = [pd.read_fwf(StringIO(s),
                      colspecs=colspecs_hyp_list,
                      skiprows=3) for s in hyp_split_trim]

assert len(hyp_list) == len(hyp_meta)
#merged the save and out catalogs
hyp_list_meta = [pd.concat([hyp_list[i], hyp_meta.iloc[[i]*len(hyp_list[i]),:].reset_index()], axis=1)
                 for i in range(len(hyp_list))]

hyp = pd.concat(hyp_list_meta, axis=0)

hyp_slvt=hyp[hyp.STAT=='SLVT']
hyp_slvt_p=hyp_slvt[hyp_slvt.IPHAS=='IP']
pd.set_option('display.max_columns', 30)
pd.set_option('display.max_rows', 584)
hyp_slvt_p

#we picked 26th of Septembre
hyp_slvt26=hyp_slvt_p[hyp_slvt_p[2]==26]
pd.set_option('display.max_columns', 36)
pd.set_option('display.max_rows', 584)
hyp_slvt26

"""Obtaining the utc date times"""

year=hyp_slvt26[0].to_numpy(dtype='int64')
month=hyp_slvt26[1].to_numpy(dtype='int64')
day=hyp_slvt26[2].to_numpy(dtype='int64')
hour=hyp_slvt26['HR'].to_numpy(dtype='int64')
minute=hyp_slvt26['MM'].to_numpy(dtype='int64')
second=hyp_slvt26['SECON'].to_numpy(dtype='int64')
microsec=round((hyp_slvt26['SECON'] % 1) * 1e6).to_numpy(dtype='int64')

num_of_event=hyp_slvt26.shape[0]

utc_time26=[]
for my_event_index in range(num_of_event):

    myevent_utc1 = obspy.UTCDateTime(year = year[my_event_index],
                                        month = month[my_event_index],
                                        day = day[my_event_index],
                                        hour = hour[my_event_index],
                                        minute = minute[my_event_index] ,
                                        second = second[my_event_index] ,
                                        microsecond = microsec[my_event_index]
                                    )
    utc_time26.append(myevent_utc1)

utc_time26

magnitudes26=hyp_slvt26[13].to_numpy() #obtaining magnitudes for 26th of september
magnitudes26

"""# Reading the data"""

st= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHE')
st+= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHN')
st+= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHZ')

tr1=st[0]
tr2=st[1]#obtaining traces
tr3=st[2]

"""# With ObsPy (Nothing Applied)

# The Effect of the Threshold

## 0.5-0.25
"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
#Value above which trigger (of characteristic function) is activated (higher threshold); first one
#Value below which trigger (of characteristic function) is deactivated (lower threshold); second one
on_of = trigger_onset(cft, 0.5, 0.25)

on_of.shape
#the first component of the matrix is the number of the detection by the algorithm

onof=on_of.shape[0]

"""- **There is a mathematical ratio; the x axis is the number of samples which is 8640009 and it is proportional to 1 day. Then, we wrote a code which lead to give us the location of the detection (in seconds). And the for loop is used dor the detection times.**"""

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

detection_times
#the dates of the detections by the algorithm (the locations of the lines that are shown in the previous presentation)

num_detect_tim=len(detection_times)
num_detect_tim
#the number of detections by the algorithm

cat_time26=len(utc_time26)
cat_time26
#the number of the dates when the earthquake occurred in the catalog

"""- **The fallowing for loop is used for comparing the dates with the catalog. It is wrtitten with three seconds tolerance. If it exceeds the date more than three seconds, the loop will not count as a correct date.**"""

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count
#the number of the correct earthquakes which is detected by the algorithm also there is three seconds tolerance!

correct_det_times
#the dates of correct earthquakes.

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])
#that for loop is written for; if the detection time is the same as in the catalog, find the magnitude from the catalog
#and bring togeher them

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 2- 0.5"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 2, 0.5)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

cat_time26=len(utc_time26)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

# bu yapÄ±yor lta sta deki magnitude dakileri
correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 2.75 - 1.75"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

cat_time26=len(utc_time26)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 5-2"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 5, 2)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

cat_time26=len(utc_time26)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 6-4"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data,int(2*df),int(df*60))
on_of = trigger_onset(cft, 6, 4)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

cat_time26=len(utc_time26)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 8-6"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 8, 6)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

cat_time26=len(utc_time26)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 10 - 8"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 10, 8)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

cat_time26=len(utc_time26)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# Overall Graphs

- **The fallowing plots shows us: the change in the number of detections, while the higher threshold value is changing. "thres" array consists of the threshold values, "num_det" array consists of the number of earthquakes detected by the algorithm, but not compared with the catalog. "num_det_cor" array consists of the number of the earthquakes which are detected by the algorithm and compared with the catalog, do not forget, there is three seconds tolerance.**
"""

thres = np.array([0.5,2,2.75,5,6,8,10])
num_det = np.array([48,19,24,14,14,16,13])
plt.plot(thres, num_det)
plt.show()
#the number of the detection that are found by lta sta plots

thres = np.array([0.5,2,2.75,5,6,8,10])
num_det_cor = np.array([2,4,6,4,4,3,3])
plt.plot(thres, num_det_cor)
plt.show()
#the number of the correct detection plots (tolerance is 3 seconds)

"""# APPENDIX 1 :  With EqCorrscan (Nothing Applied)

# The Effect of the Threshold

## 0.5-0.25
"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=0.5, trig_off=0.25)
events

len(events)

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)

num_detect_tim = detect_tim.shape[0]
num_detect_tim

cat_time26=len(utc_time26)
cat_time26

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 2- 0.5"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=2, trig_off=0.5)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)

num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])
#that for loop is written for; if the detection time is the same as in the catalog, find the magnitude from the catalog
#and bring togeher them

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 2.75 - 1.75"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 5-2"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=5, trig_off=2)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 6-4"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=6, trig_off=4)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 8-6"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=8, trig_off=6)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 10 - 8"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=10, trig_off=8)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""## Overall Graphs

- **The fallowing plots shows us: the change in the number of detections, while the higher threshold value is changing. "thres" array consists of the threshold values, "num_det" array consists of the number of earthquakes detected by the algorithm, but not compared with the catalog. "num_det_cor" array consists of the number of the earthquakes which are detected by the algorithm**
"""

thres = np.array([0.5,2,2.75,5,6,8,10])
num_det = np.array([305,146,91,39,37,40,41])
plt.plot(thres, num_det)
plt.show()
#the number of the detection that are found by lta sta plots

thres = np.array([0.5,2,2.75,5,6,8,10])
num_det_cor = np.array([9,16,14,9,9,8,7])
plt.plot(thres, num_det_cor)
plt.show()
#the number of the correct detection plots (tolerance is 3 seconds)

"""# With ObsPy (Taper Applied and Mean Removed)

## Reading the data and Preprocess
"""

st= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHE')
st+= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHN')
st+= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHZ')

st = st.copy().detrend().taper(0.05)

tr1=st[0]
tr2=st[1]
tr3=st[2]

"""# The Effect of the Threshold

## 0.5-0.25
"""

df = tr1.stats.sampling_rate

#Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
#Value above which trigger (of characteristic function) is activated (higher threshold); first one
#Value below which trigger (of characteristic function) is deactivated (lower threshold); second one
on_of = trigger_onset(cft, 0.5, 0.25)

on_of.shape
#the first component of the matrix is the number of the detection by the algorithm

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

detection_times
#the dates of the detections by the algorithm(the locations of the lines that are shown in the previous presentation)

num_detect_tim=len(detection_times)
num_detect_tim
#the number of detections by the algorithm

cat_time26=len(utc_time26)
cat_time26
#the number of the dates when the earthquake occurred in the catalog

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times
#the dates of correct earthquakes.

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 2- 0.5"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 2, 0.5)

on_of.shape
#the first component of the matrix is the number of the detectionby the algorithm

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

detection_times
#the dates of the detections by the algorithm

num_detect_tim=len(detection_times)
num_detect_tim
#the number of the detections by the algorithm

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count
#the number of the correct earthquakes which is detected by the algorithm also there is 3 seconds tolerance(by loop)

correct_det_times
#the dates of the correct earthquakes

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 2.75 - 1.75"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 5-2"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 5, 2)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 6-4"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 6, 4)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 8-6"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 8, 6)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 10 - 8"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
on_of = trigger_onset(cft, 10, 8)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""## Overall Graphs"""

thres = np.array([0.5,2,2.75,5,6,8,10])
num_det = np.array([349,587,249,40,38,30,32])
plt.plot(thres, num_det)
plt.show()
#the number of the detection that are found by lta sta plots

thres = np.array([0.5,2,2.75,5,6,8,10])
num_det_cor = np.array([7,21,18,12,11,10,9])
plt.plot(thres, num_det_cor)
plt.show()
#the number of the correct detection plots (tolerance is 3 seconds)

"""# APPENDIX 2 : With EqCorrscan ( Taper Applied and Mean Removed)

## Reading the Data
"""

st=read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHE', format="SAC")
st+=read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHZ', format="SAC")
st+=read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHN',format="SAC")

st.merge(method=0,fill_value='interpolate', interpolation_samples=1)

st = st.copy().detrend().taper(0.05)

tr1=st[0]
tr2=st[1]#obtaining traces
tr3=st[2]

"""# The Effect of the Threshold

## 0.5-0.25
"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=0.5, trig_off=0.25)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 2- 0.5"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=2, trig_off=0.5)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 2.75 - 1.75"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 5-2"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=5, trig_off=2)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim
#the number of the detections by the algorithm

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 6-4"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=6, trig_off=4)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim
#number of detection by the algorithm

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=8, trig_off=6)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim
#number of detection by the algorithm

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 10 - 8"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=10, trig_off=8)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""## Overall Graphs

- **The fallowing plots shows us: the change in the number of detections, while the higher threshold value is changing. "thres" array consists of the threshold values, "num_det" array consists of the number of earthquakes detected by the algorithm, but not compared with the catalog. "num_det_cor" array consists of the number of the earthquakes which are detected by the algorithm**
"""

thres = np.array([0.5,2,2.75,5,6,8,10])
num_det = np.array([9899,5875,2318,231,158,158,146])
plt.plot(thres, num_det)
plt.show()
#the number of the detection that are found by lta sta plots

thres = np.array([0.5,2,2.75,5,6,8,10])
num_det_cor = np.array([83,102,76,37,35,56,43])
plt.plot(thres, num_det_cor)
plt.show()
#the number of the correct detection plots (tolerance is 3 seconds)

"""# Part 2 : Comparison with Window-size

# With ObsPy (Nothing Applied)

## Reading the data
"""

st= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHE')
st+= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHN')
st+= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHZ')

tr1=st[0]
tr2=st[1]#obtaining traces
tr3=st[2]

"""# The Effect of the Window-Size

## 2-60
"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
#Value above which trigger (of characteristic function) is activated (higher threshold); first one
#Value below which trigger (of characteristic function) is deactivated (lower threshold); second one
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape
#the first component of the matrix is the number of the detection by the algorithm

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

detection_times
#the dates of the detections by the algorithm (the locations of the lines that are shown in the previous presentation)

num_detect_tim=len(detection_times)
num_detect_tim
#the number of detections by the algorithm

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times
#the dates of correct earthquakes.

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 10-80"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(10*df),int(df*80))
#Value above which trigger (of characteristic function) is activated (higher threshold); first one
#Value below which trigger (of characteristic function) is deactivated (lower threshold); second one
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 20-100"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(20*df),int(df*100))
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 20-500"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(20*df),int(df*500))
#Value above which trigger (of characteristic function) is activated (higher threshold); first one
#Value below which trigger (of characteristic function) is deactivated (lower threshold); second one
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 30-1000"""

df = tr1.stats.sampling_rate

cft = recursive_sta_lta(tr1.data, int(30*df),int(df*1000))
on_of = trigger_onset(cft, 2.75,1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 40-2000"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(40*df),int(df*2000))
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 50-5000"""

df = tr1.stats.sampling_rate

cft = recursive_sta_lta(tr1.data, int(50*df),int(df*5000))
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""## Overall Graphs

- **The fallowing plots shows us: the change in the number of detections, while the higher window-size value is changing. "window" array consists of the higher window-size values, "num_det" array consists of the number of earthquakes detected by the algorithm, but not compared with the catalog. "num_det_cor" array consists of the number of the earthquakes which are detected by the algorithm and compared with the catalog, do not forget, there is three seconds tolerance.**
"""

window = np.array([60,80,100,500,1000,2000,5000])
num_det = np.array([24,13,11,12,7,4,4])
plt.plot(window, num_det)
plt.show()
#the number of the detection that are found by lta sta plots

window = np.array([60,80,100,500,1000,2000,5000])
num_det_cor = np.array([6,3,1,1,1,1,1])
plt.plot(window, num_det_cor)
plt.show()
#the number of the correct detection plots (tolerance is 3 seconds)

"""# APPENDIX 3 : With EqCorrscan (Nothing Applied)

## Reading the data
"""

st=read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHE', format="SAC")
st+=read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHZ', format="SAC")
st+=read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHN',format="SAC")

st.merge(method=0,fill_value='interpolate', interpolation_samples=1)

tr1=st[0]
tr2=st[1]#obtaining traces
tr3=st[2]

"""# The Effect of the Window-size

## 2-60
"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 10-80"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=10, ltalen=80, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 20-100"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=20, ltalen=100, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 20-500"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=20, ltalen=500, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 30-1000"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=30, ltalen=1000, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 40-2000"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=40, ltalen=2000, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 50-5000"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=50, ltalen=5000, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""## Overall Graphs

- **The fallowing plots shows us: the change in the number of detections, while the higher window-size value is changing. "window" array consists of the higher window-size, "num_det" array consists of the number of earthquakes detected by the algorithm, but not compared with the catalog. "num_det_cor" array consists of the number of the earthquakes which are detected by the algorithm and compared with the catalog, do not forget, there is three seconds tolerance.**
"""

window = np.array([60,80,100,500,1000,2000,5000])
num_det = np.array([91,37,29,30,28,26,16])
plt.plot(window, num_det)
plt.show()
#the number of the detection that are found by lta sta plots

window = np.array([60,80,100,500,1000,2000,5000])
num_det_cor = np.array([14,7,3,4,3,2,2])
plt.plot(window, num_det_cor)
plt.show()
#the number of the correct detection plots (tolerance is 3 seconds)

"""# With ObsPy ( Taper Apllied and Mean Removed)

## Reading the Data
"""

st= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHE')
st+= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHN')
st+= obspy.read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHZ')

st = st.copy().detrend().taper(0.4)

tr1=st[0]
tr2=st[1]#obtaining traces
tr3=st[2]

"""# The Effect of the Window-Size

## 2-60
"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(2*df),int(df*60))
#Value above which trigger (of characteristic function) is activated (higher threshold); first one
#Value below which trigger (of characteristic function) is deactivated (lower threshold); second one
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

detection_times

num_detect_tim=len(detection_times)
num_detect_tim
#the number of detections by the algorithm

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times
#the dates of correct earthquakes.

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 10-80"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(10*df),int(df*80))
#Value above which trigger (of characteristic function) is activated (higher threshold); first one
#Value below which trigger (of characteristic function) is deactivated (lower threshold); second one
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 20-100"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(20*df),int(df*100))
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.xlabel('magnitude')
plt.ylabel('number of eq')
plt.legend()
plt.show

"""# 20-500"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(20*df),int(df*500))
#Value above which trigger (of characteristic function) is activated (higher threshold); first one
#Value below which trigger (of characteristic function) is deactivated (lower threshold); second one
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 30-1000"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(30*df),int(df*1000))
on_of = trigger_onset(cft, 2.75,1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 40-2000"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(40*df),int(df*2000))
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 50-5000"""

df = tr1.stats.sampling_rate

# Characteristic function and trigger onsets
cft = recursive_sta_lta(tr1.data, int(50*df),int(df*5000))
on_of = trigger_onset(cft, 2.75, 1.75)

on_of.shape

onof=on_of.shape[0]

#the start times for the earthquake
detection_times=[]
for i in np.arange(0, onof):
    time=tr1.stats.starttime + on_of[i,0]*86400.08/8640009
    detection_times.append(time)

num_detect_tim=len(detection_times)

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detection_times[time_index] and utc_time26[cat_event_index]+3 >= detection_times[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""## Overall Graphs

- **The fallowing plots shows us: the change in the number of detections, while the higher window-size value is changing. "window" array consists of the higher window-size, "num_det" array consists of the number of earthquakes detected by the algorithm, but not compared with the catalog. "num_det_cor" array consists of the number of the earthquakes which are detected by the algorithm and compared with the catalog, do not forget, there is three seconds tolerance.**
"""

window = np.array([60,80,100,500,1000,2000,5000])
num_det = np.array([243,35,26,29,13,6,5])
plt.plot(window, num_det)
plt.show()
#the number of the detection that are found by lta sta plots

window = np.array([60,80,100,500,1000,2000,5000])
num_det_cor = np.array([18,10,7,5,2,2,2])
plt.plot(window, num_det_cor)
plt.show()
#the number of the correct detection plots (tolerance is 3 seconds)

"""# APPENDIX 4 : With EqCorrscan (Taper Applied and Mean Removed)

## Reading the Data
"""

st=read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHE', format="SAC")
st+=read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHZ', format="SAC")
st+=read('/Users/korayaydogan/Downloads/SLVT/2019-0926000000_SLVT.HHN',format="SAC")

st.merge(method=0,fill_value='interpolate', interpolation_samples=1)

st = st.copy().detrend().taper(0.05)

tr1=st[0]
tr2=st[1]#obtaining traces
tr3=st[2]

"""# The Effect of the Window-size

## 2-60
"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=2, ltalen=60, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 10-80"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=10, ltalen=80, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""# 20-100"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=20, ltalen=100, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 20-500"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=20, ltalen=500, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 30-1000"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=30, ltalen=1000, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 40-2000"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=40, ltalen=2000, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()
plt.show()

"""# 50-5000"""

events=eqcorrscan.utils.picker.stalta_pick(st,  stalen=50, ltalen=5000, trig_on=2.75, trig_off=1.75)
events

for i in range(len(events)):
    pprint(events.picks[i])
    print("\n \n")

detect_timlst=[]
for i in range(len(events.picks)):
    detect_timlst.append(obspy.UTCDateTime(events.picks[i].time))
detect_timlst

detect_tim = np.asarray(detect_timlst)
num_detect_tim = detect_tim.shape[0]
num_detect_tim

count=0
correct_det_times=[]
for time_index in range(num_detect_tim-1):
    for cat_event_index in range(cat_time26-1):
        if utc_time26[cat_event_index]-3 <= detect_tim[time_index] and utc_time26[cat_event_index]+3 >= detect_tim[time_index]:
            count+=1
            correct_det_times.append(utc_time26[cat_event_index])

count

correct_det_times

correct_det_mag=[]
for det_time in range(len(correct_det_times)):
    for event_time in range(len(utc_time26)):
        if correct_det_times[det_time]==utc_time26[event_time]:
            correct_det_mag.append(magnitudes26[event_time])

correct_det_mag
#magnitudes

bins = np.arange(0,6.1,0.1)
ylim = np.arange(1,20,1)
detections = correct_det_mag
catalog = magnitudes26

plt.hist([detections, catalog], bins, label = ["detections","catalog"])
plt.legend()

"""## Overall Graphs

- **The fallowing plots shows us: the change in the number of detections, while the higher threshold value is changing. "window" array consists of the window-size values, "num_det" array consists of the number of earthquakes detected by the algorithm, but not compared with the catalog. "num_det_cor" array consists of the number of the earthquakes which are detected by the algorithm**
"""

window = np.array([60,80,100,500,1000,2000,5000])
num_det = np.array([2318,247,125,119,140,61,75])
plt.plot(window, num_det)
plt.show()
#the number of the detection that are found by lta sta plots

window = np.array([60,80,100,500,1000,2000,5000])
num_det_cor = np.array([76,47,28,18,22,7,11])
plt.plot(window, num_det_cor)
plt.show()
#the number of the correct detection plots (tolerance is 3 seconds)

"""# Appendix / Brief Summary / Inferences

- **Since the notebook is too long, let us give you some inferences about these models:**
   - **As the threshold value increases the number of detection is decreased especially the model loses its efficiency on the weak earthquakes, but as you read the biggest earthquake is detected though.**
   - **Again, as the window-size value increases the number of detection is again decreased. We can assimilate it as threshold effect. But, as you saw, the big earthquake(5.8) is always detected.**
   - **Eqcorrscan package maybe is better than ObsPy since the source code of the Eqcorrscan showed us that it makes some elimination on the detections. But, again we want to say that Eqcorrscan module gives us the detection times twice. It is bad for us but, the detections, that are found by Eqcorrscan, make more sense than ObsPy.**
   - **Tapering and removing mean is beneficial for us, since they prevent deconvolution. And, this circumstance makes the model better. Also, once we use taper and remove the mean, the number of detection is increased. But, as you saw the best model worked on Eqcorrscan(mean removed & taper applied).**

- **Also we wanted to share with you another parameters and their effects on the model:**
    - **Window-sizes: 2-60, thresholds: 10-4, number of detection: 12, max_magnitude: 5.8 , min_magnitude:2.2**
    - **Window-sizes: 2-30, thresholds: 10-4, number of detection: 0, max_magnitude: none , min_magnitude:none**
    - **Window-sizes: 2-30, thresholds: 12-4, number of detection: 0, max_magnitude: none , min_magnitude:none**
    - **Window-sizes: 2-30, thresholds: 8-4, number of detection: 4, max_magnitude: 3.7 , min_magnitude:3**
    - **Window-sizes: 2-30, thresholds: 8-5, number of detection: 4, max_magnitude: 3.7 , min_magnitude:3**
    - **Window-sizes: 2-30, thresholds: 8-6, number of detection: 4, max_magnitude: 3.7 , min_magnitude:3**
    - **Window-sizes: 2-30, thresholds: 10-6, number of detection: 0, max_magnitude: 3.7 , min_magnitude:3**

- **Also, we wanted to say the best two parameters and package name: (you can view them on the Eqcoorscan and tapered section)**
    - **Window-sizes: 2-60, thresholds: 2-0.5, package name: Eqcorrscan(Attempt)**
    - **Window-sizes: 2-60, thresholds: 2.75-1.75, package name: Eqcorrscan(Attempt)**
    - **Window-sizes: 2-60, thresholds: 2.75-1.75, package name: ObsPy**
"""



